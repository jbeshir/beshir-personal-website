---
layout: ../../layouts/summary.astro
title: "A Whirlwind Tour of LW Rationality: 6&nbsp;Books in 32 Pages - Becoming Stronger"
subpost: "true"
date: "2016-07-09"
categories: 
  - "rationality"
---

[(Back to "Mere Goodness")](/summaries/a-whirlwind-tour-of-lw-rationality-mere-goodness)

### Becoming Stronger X: Yudkowsky’s Coming Of Age

Yudkowsky grew up in an environment which praised experience over intelligence as justification for everything, including religion. This led them to the opposite, an affective death spiral around intelligence as the solution to everything. They thought that being very intelligent meant being very moral. They tended to go too far the other way in reaction to someone else’s stupidity. ([My Childhood Death Spiral](http://lesswrong.com/lw/ty/my_childhood_death_spiral/))

Because previous definitions of intelligence had been lacking, they thought it could not be defined tidily. This led to avoiding premature answers. They believed the field of AI research was sick; this led to studying cognitive science. Errors which lead to studying more are better errors. ([My Best And Worst Mistake](http://lesswrong.com/lw/tz/my_best_and_worst_mistake/)) They regarded regulation of technology as bad, and this reduced attention to existential risks. When convinced risks existed, rather than reviewing mistakes, they just decided we needed AI first. ([Raised In Technophilia](http://lesswrong.com/lw/u0/raised_in_technophilia/))

They were good at refuting arguments, and felt they were winning the debate on whether intelligence implied morality. They had a rationale for proceeding with their best ideas, without resolving confusion. Reality does not care whether you are using your best ideas. You can’t rely on anyone giving you a flawless argument, and you can’t work around underlying confusion. ([A Prodigy Of Refutation](http://lesswrong.com/lw/u1/a_prodigy_of_refutation/), [The Sheer Folly Of Callow Youth](http://lesswrong.com/lw/u2/the_sheer_folly_of_callow_youth/))

An incongruous thought, coupled with some perfectionism, and viewing less than morally upright interactions as unacceptable, led to investigating seriously. Doing that, regardless of reason, led to pursuing a backup plan. ([That Tiny Note Of Discord](http://lesswrong.com/lw/u7/that_tiny_note_of_discord/)) That they were pursuing a backup plan gave them a line of retreat for their earlier views, but they only shifted gradually, without acknowledging fundamental errors. ([Fighting A Rearguard Action Against The Truth](http://lesswrong.com/lw/u8/fighting_a_rearguard_action_against_the_truth/))

They only saw the error when they realised that a mind was an optimisation process which pumps reality towards outcomes, and you could pump towards any outcomes. ([My Naturalistic Awakening](http://lesswrong.com/lw/u9/my_naturalistic_awakening/)) They realised that they could have unrefuted arguments, and nature could still kill them if the choice was wrong. Their trust in following patterns broke, and they began studying rationality. ([The Magnitude Of His Own Folly](http://lesswrong.com/lw/ue/the_magnitude_of_his_own_folly/)) We all need to lose our assumption of fairness. ([Beyond The Reach Of God](http://lesswrong.com/lw/uk/beyond_the_reach_of_god/)) They realised that an idea seeming very good didn’t permit being sure; it needed to be provably equivalent to any correct alternative, like Bayesian probability. ([My Bayesian Enlightenment](http://lesswrong.com/lw/ul/my_bayesian_enlightenment/))

They recognise that there are people more formidable than them, and hope that their writings might find a younger one of them who can then exceed them. ([The Level Above Mine](http://lesswrong.com/lw/ua/the_level_above_mine/))

### Becoming Stronger Y: Challenging The Difficult

Wanting to become stronger means reacting to flaws by doing what you can to repair them rather than with resignation. Do not ritualistically confess your flaws unless you include what you intend to do about them. ([Tsuyoku Naritai! (I Want To Become Stronger)](http://lesswrong.com/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/)) If you are ashamed of wanting to do better than others, you will not make a real effort to seek higher targets. You should always reach higher, without shame. ([Tsuyoku Vs The Egalitarian Instinct](http://lesswrong.com/lw/h9/tsuyoku_vs_the_egalitarian_instinct/))

The difference between saying that you are going to _do something_, and that you are going to _try to do something_, is that the latter makes you satisfied with a plan, rather than with success, and allows the part where the plan has to maximise your odds of success to get lost. Don’t try your best; either win or fail. ([Trying To Try](http://lesswrong.com/lw/uh/trying_to_try/)) People don’t make genuine efforts to win even for five minutes. ([Use The Try Harder, Luke](http://lesswrong.com/lw/ui/use_the_try_harder_luke/))

A desperate effort is a level above wanting to become stronger, where you try as though your life were at stake. And there is a step above that, an extraordinary effort; it requires being willing to go outside of a comfortable routine, tackle difficulties you don’t have a mental routine for, and bypass usual patterns, in order to achieve an outcome that is not the default that you care greatly about. It is riskier than even a desperate effort. ([Make An Extraordinary Effort](http://lesswrong.com/lw/uo/make_an_extraordinary_effort/))

A problem being impossible sometimes only means that when we query our brain for a strategy, we can’t think of one. This is not the same as being proven to be impossible. Genuine effort over years can find routes forward. Reality can uncaringly demand the impossible. We should resist our urge to find rationalisations for why the problem doesn’t matter ([On Doing The Impossible](http://lesswrong.com/lw/un/on_doing_the_impossible/)), and sometimes we should _shut up and do the impossible_; take success at the impossible as our goal and accept nothing less. ([Shut Up And Do The Impossible!](http://lesswrong.com/lw/up/shut_up_and_do_the_impossible/))

We need to ask ourselves what we want, what it will require to accomplish, and set out to do it with what we know. ([Final Words](http://lesswrong.com/lw/cl/final_words/))

### Becoming Stronger Z: The Craft and the Community

The prevalence of religion, even in scientific circles, warns us that the baseline grasp of rationality is very low. Arguing against religion specifically fails to solve the underlying problem. We should also be trying to _raise the sanity waterline_. ([Raising The Sanity Waterline](http://lesswrong.com/lw/1e/raising_the_sanity_waterline/))

A reason that people don’t want to learn more about rationality is that they don’t see people who know about it as happier or more successful. A large part of this is that even the people who know a lot about it still know very little, compared to experts in other fields; we have not systematised it as a field of study, subject to large-scale investment and experimentation. One reason for this is that traditional rationalists/skeptics do not see lack of visible formidability and say that we must be doing something wrong. We treat it as a mere hobby horse. ([A Sense That More Is Possible](http://lesswrong.com/lw/2c/a_sense_that_more_is_possible/)) It can take more than an incremental step in the direction of rationality to get an incremental increase in winning. ([Incremental Progress And The Valley](http://lesswrong.com/lw/7k/incremental_progress_and_the_valley/))

Martial arts dojos suffer from _epistemic viciousness_; a treatment of the master as sacred, exaltation of historic knowledge over discovery, a lack of data, and a pretense that lack of data isn’t a real problem. Hypothetical rationality dojos risk the same problems. ([Epistemic Viciousness](http://lesswrong.com/lw/2i/epistemic_viciousness/)) If an air of authority can substitute for evidence, traditions can proliferate and wield influence without evidence. ([Schools Proliferating Without Evidence](http://lesswrong.com/lw/2j/schools_proliferating_without_evidence/))

Verification methods can be stratified into three levels. _Reputational_ verification is the basic practice of trying to ground reputations in some real world or competitive performance. _Experimental_ verification is randomised, replicable testing, although this can involve very simple measures that are only correlated with the variables of interest. _Organisational_ verification is that which, when everyone knows the process, is resistant enough to gaming to continue working. ([3 Levels Of Rationality Verification](http://lesswrong.com/lw/2s/3_levels_of_rationality_verification/))

Groups which do not concern themselves with rationality can praise agreement, encourage the less agreeing to leave, and enter an affective death spiral, which binds them all together and makes them cooperate. Typical rationalist groups do not cooperate; they speak and applaud disagreement but not agreement. If you are outperformed by irrational groups, then you are not rational, because rationality is about winning. Actual rationality should involve being better at coordinating, and we should work out how to be. Being half a rationalist is dangerous. ([Why Our Kind Can't Cooperate](http://lesswrong.com/lw/3h/why_our_kind_cant_cooperate/), [Bayesians Vs Barbarians](http://lesswrong.com/lw/5f/bayesians_vs_barbarians/)) Until atheist groups can outperform religious groups at mobilisation and output, any increase in atheism is a hollow victory. ([Can Humanism Match Religion's Output?](http://lesswrong.com/lw/5t/can_humanism_match_religions_output/)) We need new models of community to replace the old, with new goals. ([Church Vs Taskforce](http://lesswrong.com/lw/5v/church_vs_taskforce/))

Do not punish people for being more patient than you; you should _tolerate tolerance_. ([Tolerate Tolerance](http://lesswrong.com/lw/42/tolerate_tolerance/)) We incentivise groups to improve by rejecting joining them if they don’t meet our standards. The non-conformist crowd tends to ask way too much. If joining a project is good, you should do it if the problems are not too distracting, or if you could fix the problems. If you don’t see a problem as worth putting in the time to fix, it is not worth avoiding a group for. If we want to get anything done, we need to move in the direction of joining groups and staying in them. ([Your Price For Joining](http://lesswrong.com/lw/5j/your_price_for_joining/))

Many causes benefit from the spread of rationality. We should not think of other good causes as in competition for a limited pool of reasonable thinkers, but instead cooperate with them to increase the number of reasonable thinkers. We should think of ourselves as all part of one common project of human progress. ([Rationality: Common Interest Of Many Causes](http://lesswrong.com/lw/66/rationality_common_interest_of_many_causes/)) We are very bad at coordinating to fulfil aligned preferences of individuals. Large flows of money tend to be controlled by the incentives of organisations. ([Helpless Individuals](http://lesswrong.com/lw/64/helpless_individuals/))

Donating time is inefficient compared to donating money. Allocating money is how we allocate resources. _Money is the unit of caring_. If you’ll never spend it, you don’t care. ([Money: The Unit Of Caring](http://lesswrong.com/lw/65/money_the_unit_of_caring/)) We enjoy having done kind things, but the things that bring us enjoyment often do much less good than calculated effort, and enjoyment and social status can be had much cheaper when you don’t try to achieve them through your giving. Get enjoyment, status, and results separately; _purchase fuzzies and utilons separately_. ([Purchase Fuzzies And Utilons Separately](http://lesswrong.com/lw/6z/purchase_fuzzies_and_utilons_separately/))

The _bystander effect_ is a bias in which a group is less likely to react to an emergency than a single individual. ([Bystander Apathy](http://lesswrong.com/lw/9j/bystander_apathy/)) This applies to problems encountered over the Internet, where you are always observing them as part of a group of strangers. ([Collective Apathy And The Internet](http://lesswrong.com/lw/9m/collective_apathy_and_the_internet/))

When we write advice, we are not working from universal generalisations, but surface level tricks. This means it validly works for some people but not others. We should _beware other-optimising_, because we are not good at knowing what works for others, and beware assuming that other people are simply not trying what worked for us. ([Beware Of Other-Optimizing](http://lesswrong.com/lw/9v/beware_of_otheroptimizing/)) Practical advice based on established theories tends to be more generalisable. ([Practical Advice Backed By Deep Theories](http://lesswrong.com/lw/d4/practical_advice_backed_by_deep_theories/))

The danger of underconfidence is missing opportunities and not making a genuine effort. Sticking to things you always win at is a way smart people become stupid. You should seriously try to win, but aim for challenges you might lose at. When considering a habit of thought, ask whether it makes you stronger or weaker. ([The Sin Of Underconfidence](http://lesswrong.com/lw/c3/the_sin_of_underconfidence/))

There is more absent than present in these writings. Defeating akrasia and coordinating groups are particular absences. But, hopefully, there is enough to overcome the barriers to getting started in the matter of rationality without immediately going terribly wrong. The hope is that this art of answering confused questions will be enough to _go and complete the rest_. This will require drawing on many sources, and require having some specific motivating goal. _Go forth and create the art_, and return to tell others what you learned. ([Go Forth And Create The Art!](http://lesswrong.com/lw/c4/go_forth_and_create_the_art/))
