---
layout: ../../layouts/summary.astro
title: "A Whirlwind Tour of LW Rationality: 6&nbsp;Books in 32 Pages - Mere Reality"
date: "2016-07-09"
categories: 
  - "rationality"
---

[(Back to "The Machine In The Ghost")](/summaries/a-whirlwind-tour-of-lw-rationality-the-machine-in-the-ghost)

### Mere Reality O: Lawful Truth

Apparently independent surface-level rules of reality follow from more basic common rules. This means you can’t have a consistent world in which some surface-level rules keep working for the same reasons they always worked and others don’t work. ([Universal Fire](http://lesswrong.com/lw/hq/universal_fire/))

The universe almost certainly runs on absolute laws with no exceptions, although we have a much greater degree of uncertainty as to what those laws are. This feels like an unreasonably uncompromising social move to people used to thinking about human or moral laws. ([Universal Law](http://lesswrong.com/lw/hr/universal_law/))

Reality remains uncertain because we don’t know the laws, because it isn’t feasible to work out the exact consequences of the laws, and we don’t know which human in reality we will perceive ourselves as being. Reality is not fundamentally messy; only our perspective on it is. ([Is Reality Ugly?](http://lesswrong.com/lw/ms/is_reality_ugly/))

Bayesian theorems are attractive because they’re laws, rather than because Bayesian methods are always the most practical tool. ([Beautiful Probability](http://lesswrong.com/lw/mt/beautiful_probability/)) Mutual information is Bayesian evidence; anything which generates better than random beliefs must do so through processing Bayesian evidence. ([Searching For Bayes-Structure](http://lesswrong.com/lw/o7/searching_for_bayesstructure/))

A scientist who is not more selective in their beliefs outside the laboratory than a typical person has memorised rules to get by, but lacks understanding of what those rules mean. ([Outside The Laboratory](http://lesswrong.com/lw/gv/outside_the_laboratory/))

No part of a system can violate the first law of thermodynamics, conservation of energy, and so we reject systems claiming to. Liouville’s theorem says the space of possible states of a system is conserved; for any part whose state becomes more certain, another part becomes less certain.

The second law of thermodynamics, that total entropy cannot decrease, is a corollary. Maxwell’s demon is a hypothetical entity which lets only fast-moving gas molecules through a barrier without generating entropy, decreasing entropy. If you knew the state of the gas for free, you could create one. This means that knowing things about the universe without observing them and generating entropy in the process would be a violation of the second law of thermodynamics. ([The Second Law Of Thermodynamics, And Engines Of Cognition](http://lesswrong.com/lw/o5/the_second_law_of_thermodynamics_and_engines_of/))

When people try to justify something without evidence, they often construct theories complicated enough that they can make a mistake and miss it, similar to people designing perpetual motion machines. ([Perpetual Motion Beliefs](http://lesswrong.com/lw/o6/perpetual_motion_beliefs/))

### Mere Reality P: Reductionism 101

For some questions, we should, rather than trying to answer or prove them nonsensical, try to identify why we feel a question exists. The result should dissolve that feeling. ([Dissolving The Question](http://lesswrong.com/lw/of/dissolving_the_question/))

A cue that you’re dealing with a confused question is when you cannot imagine any observation that answers it. ([Wrong Questions](http://lesswrong.com/lw/og/wrong_questions/)) One way forward is to ask “Why do I think [thing]?” rather than “Why [thing]?”. The new question will lead you to the entanglement of your beliefs with reality that generated the belief, if it is not confused, and an explanation of your mind otherwise. ([Righting A Wrong Question](http://lesswrong.com/lw/oh/righting_a_wrong_question/))

The _mind projection fallacy_ is treating properties of our perception of a thing as inherent attributes of it. ([Mind Projection Fallacy](http://lesswrong.com/lw/oi/mind_projection_fallacy/)) The probability of an event is a property of our perception, not the event. ([Probability Is In The Mind](http://lesswrong.com/lw/oj/probability_is_in_the_mind/)) We call something chaotic when we can’t predict it, but miss that this is a fact about our ability to predict. This causes us to miss opportunities to improve. ([Chaotic Inversion](http://lesswrong.com/lw/wb/chaotic_inversion/)) Rather than viewing reality as weird, resist getting caught up in incredulity, and let intuition adjust to view reality as normal. ([Think Like Reality](http://lesswrong.com/lw/hs/think_like_reality/))

Probability assignments are not well modelled as true or false, but as having a level of accuracy. Your beliefs about your own beliefs have different accuracy to those beliefs. Differing beliefs are only differing truths insofar as accurate statements about your own map differ; this is not accurate statements about reality differing between people, because _the map is not the territory_. ([Qualitatively Confused](http://lesswrong.com/lw/om/qualitatively_confused/)) The concept of a thing is not the same as the thing. If a person thinks a thing is two separate things, described by separate concepts, those concepts may differ despite referring to the same thing. ([The Quotation is Not The Referent](http://lesswrong.com/lw/ok/the_quotation_is_not_the_referent/))

Reductionism is disbelief in a particular form of the mind projection fallacy. It is useful for us to use different models for different scales of reality, but this is an aspect of what is useful for us, not an aspect of the different scales of reality, and does not mean that they are governed differently. ([Reductionism](http://lesswrong.com/lw/on/reductionism/))

Explaining and _explaining away_ are different. Non-fundamental things still exist. Explaining away something only removes it from the map; it was never in the territory. ([Explaining Vs Explaining Away](http://lesswrong.com/lw/oo/explaining_vs_explaining_away/)) A thing is only reduced if you know the explanation; knowing one exists only changes literary genre. ([Fake Reductionism](http://lesswrong.com/lw/op/fake_reductionism/)) We can tell human stories about humans. A non-anthropomorphic view of the world helps broader stories. ([Savanna Poets](http://lesswrong.com/lw/oq/savanna_poets/))

### Mere Reality Q: Joy In The Merely Real

You should be able to care about knowable, unmagical things. The alternative is existential ennui, because everything is knowable. ([Joy In The Merely Real](http://lesswrong.com/lw/or/joy_in_the_merely_real/)) Taking joy only in discovering something no one else knows makes joy scarce; instead, find joy in all discoveries. ([Joy In Discovery](http://lesswrong.com/lw/os/joy_in_discovery/))

By placing hope in and celebrating true things, you direct your emotions into reality rather than fiction. ([Bind Yourself To Reality](http://lesswrong.com/lw/ot/bind_yourself_to_reality/)) If we lived in a world with magic, it would seem as mundane as science. If you can’t be excited by reality or put in great effort to change the world here, you wouldn’t there. ([If You Demand Magic, Magic Won't Help](http://lesswrong.com/lw/ou/if_you_demand_magic_magic_wont_help/))

Many of our abilities, such as ‘vibratory telepathy’ (speech) and ‘psychometric tracing’ (writing) would be amazing magical powers if only a few had them. Even more so for the ‘Ultimate Power’; possessing a small imperfect echo of the universe, and searching through probability to find paths to a desired future. We shouldn’t think less of them for commonality. ([Mundane Magic](http://lesswrong.com/lw/ve/mundane_magic/))

Settled science is as beautiful as new science. Textbooks will offer you careful explanations, examples, test problems, and likely true information. Pop science articles offer wrong explanations of results the author likely didn’t understand, and have a high chance of not replicating. You cannot understand the world if you only read science reporting. ([The Beauty Of Settled Science](http://lesswrong.com/lw/ow/the_beauty_of_settled_science/), [Amazing Breakthrough Day: April 1st](http://lesswrong.com/lw/ox/amazing_breakthrough_day_april_1st/))

Irreligious attempts to imitate religious trappings and hymns always suck. However, a sense of awe is not exclusive to religion. There are things which would have been a good idea even if religion had never existed to imitate that can be awe-inspiring, such as space shuttle launches. For those things, the awe remains when they are mundane and explained. ([Is Humanism A Religion-Substitute?](http://lesswrong.com/lw/oy/is_humanism_a_religionsubstitute/))

Things become more desirable as they become less attainable; this is _scarcity_. Similarly, forbidden information appears more important. When something is attained it stops being scarce, leading to frustration. ([Scarcity](http://lesswrong.com/lw/oz/scarcity/)) If Science was secret, it would become fascinating. ([To Spread Science Keep It Secret](http://lesswrong.com/lw/p0/to_spread_science_keep_it_secret/), [Initiation Ceremony](http://lesswrong.com/lw/p1/initiation_ceremony/))

Mysteriousness, faith, unique incommunicability, separation of domains, and experientialism shield from criticism, and declare the mundane boring. We shouldn’t have them. ([The Sacred Mundane](http://lesswrong.com/lw/57/the_sacred_mundane/))

### Mere Reality R: Physicalism 201

Concepts such as ‘your hand’, describe the same part of the world as lower level concepts, such as ‘your palm and fingers’. They do not vary independently, but still ‘exist’. ([Hands Vs Fingers](http://lesswrong.com/lw/p2/hand_vs_fingers/)) Concepts such as ‘heat’ and ‘motion’, can also refer to the same thing, even if you can imagine a world where they refer to separate things. ([Heat Vs Motion](http://lesswrong.com/lw/p4/heat_vs_motion/)) Concepts note only that a cluster exists, and do not define it exactly. ([Reductive Reference](http://lesswrong.com/lw/p6/reductive_reference/))

Understanding how higher-level things such as ‘anger’ are created by lower-level things requires discovering the explanation, not just assertion. ([Angry Atoms](http://lesswrong.com/lw/p3/angry_atoms/)) Rationality is not social rules; rationality is how our brain works. ([A Priori](http://lesswrong.com/lw/k2/a_priori/)) Reality is that which sometimes violates expectations and surprises you. ([Reductive Reference](http://lesswrong.com/lw/p6/reductive_reference/) again)

The brain is a complex organ made of neurons. ([Brain Breakthrough! It's Made Of Neurons!](http://lesswrong.com/lw/p5/brain_breakthrough_its_made_of_neurons/)) Before we realised that thinking involved a complex organ, Animism was a reasonable error. ([When Anthropomorphism Became Stupid](http://lesswrong.com/lw/t5/when_anthropomorphism_became_stupid/)) A proposed entity is supernatural if it is irreducibly complex. Because our brains are reducible, no set of expectations can require irreducible complexity, but some expectations make irreducibility more likely than others. ([Excluding The Supernatural](http://lesswrong.com/lw/tv/excluding_the_supernatural/), [Psychic Powers](http://lesswrong.com/lw/tw/psychic_powers/))

A _zombie_, in the philosophical sense, is a hypothetical being which looks and behaves exactly like a human, including talking about being conscious, but is not conscious. It is alleged that if it is a coherent hypothetical, consciousness must be extra-physical. It is not coherent if ‘process which causes talking about consciousness’ and ‘consciousness’ refer to the same part of the world. We should believe they do, because the alternative is more complex. ([Zombies! Zombies?](http://lesswrong.com/lw/p7/zombies_zombies/), [Zombie Responses](http://lesswrong.com/lw/p8/zombie_responses/), [Zombies: The Movie](http://lesswrong.com/lw/pn/zombies_the_movie/)) It is correct to believe in unobservable things if and only if the most succinct model of reality predicts them. ([Belief In The Implied Invisible](http://lesswrong.com/lw/pb/belief_in_the_implied_invisible/))

The _generalised anti-zombie principle_ is that any change we shouldn’t expect to change the reasons we talk about consciousness is one we should expect to leave us still conscious. ([The Generalized Anti-Zombie Principle](http://lesswrong.com/lw/p9/the_generalized_antizombie_principle/)) Conceivably, one could replace a human with a giant look-up table (GLUT) which would seem to violate this principle, but the process which selected the GLUT to use would need to have been conscious and make all the same decision-making choices as you in doing so. ([GAZP Vs GLUT](http://lesswrong.com/lw/pa/gazp_vs_glut/))

### Mere Reality S: Quantum Physics and Many Worlds

_(This sequence is controversial; mean probability assigned to MWI was 56.5% in_ [_the 2011 survey_](http://lesswrong.com/lw/8p4/2011_survey_results/)_)_

Quantum mechanics is not intuitive; this is a flaw in intuition. ([Quantum Explanations](http://lesswrong.com/lw/pc/quantum_explanations/))

Reality is comprised of _configurations_ with complex-valued _amplitudes_, and rules for calculating amplitude flows into other configurations. We cannot measure amplitudes directly, only the ratio of absolute squares of some configurations. ([Configurations And Amplitude](http://lesswrong.com/lw/pd/configurations_and_amplitude/)) You sum all amplitude flows into a configuration to get its amplitude. Amplitude flows that put the same types of particle in the same places flow into the same configuration, even if the particles came from different places. Which configurations are the same is observable fact. If amplitude flows have opposite sign, they can cancel out to zero. If either flow had been absent, the configuration would have had non-zero amplitude. ([Joint Configurations](http://lesswrong.com/lw/pe/joint_configurations/))

A configuration is defined by all particles. If amplitude flows alter a particle’s state, then they cannot flow into the same configuration as amplitude flows which do not alter it. Thus, measuring amplitude flows stops them from flowing to the same configurations. ([Distinct Configurations](http://lesswrong.com/lw/pf/distinct_configurations/))

_Collapse_ theories propose that at some point before a measurement reaches a human brain, there is a waveform collapse leaving only one random configuration with non-zero amplitude, discarding other amplitude flows. _Many Worlds_ proposes that this doesn’t happen; configurations where we observe and don’t observe a measurement both exist with non-zero amplitude, too different from each other for their amplitude flows to flow into common configurations; we have _macroscopic decoherence_. Collapse would be very different to other physics. ([Collapse Postulates](http://lesswrong.com/lw/q6/collapse_postulates/)) Living in multiple worlds is the same as living in one; we shouldn’t be unsettled by it. ([Living In Many Worlds](http://lesswrong.com/lw/qz/living_in_many_worlds/))

Decoherence is simpler ([Decoherence Is Simple](http://lesswrong.com/lw/q3/decoherence_is_simple/)), while making the same predictions. ([Decoherence Is Falsifiable And Testable](http://lesswrong.com/lw/q4/decoherence_is_falsifiable_and_testable/)) _Privileging the hypothesis_ is selecting an unlikely hypothesis for attention, causing confirmation bias. Historical accident has privileged collapse theories ([Privileging The Hypothesis](http://lesswrong.com/lw/19m/privileging_the_hypothesis/), [If Many-Worlds Had Come First](http://lesswrong.com/lw/q7/if_manyworlds_had_come_first/), [Many Worlds, One Best Guess](http://lesswrong.com/lw/q8/many_worlds_one_best_guess/)) because people didn’t think of themselves as made of particles. ([Where Philosophy Meets Science](http://lesswrong.com/lw/pg/where_philosophy_meets_science/), [Thou Art Physics](http://lesswrong.com/lw/r0/thou_art_physics/)) Declaring equations to be meaningless is wrong; there is something described. ([Quantum Non-Realism](http://lesswrong.com/lw/q5/quantum_nonrealism/))

### Mere Reality T: Science and Rationality

Science is supposed to replace theories when experiments falsify them in favour of new theories, and is uninterested in simpler theories making the same predictions. This leads to different results than application of probability theory. ([The Dilemma: Science or Bayes?](http://lesswrong.com/lw/qa/the_dilemma_science_or_bayes/)) Science is this way because it doubts that flawed humans debating elegance will reach truth if not forced to experiment. Science distrusts your rationality. ([Science Doesn't Trust Your Rationality](http://lesswrong.com/lw/qb/science_doesnt_trust_your_rationality/))

Science doesn’t help you get answers to questions that are not testable in the present day. It is incorrect to dismiss theories answering those questions because they’re scientifically unproven. You must try to use your reason. ([When Science Can't Help](http://lesswrong.com/lw/qc/when_science_cant_help/)) Science does not judge your choice of hypothesis, and only requires you react to overwhelming evidence. It accepts slow, generational progress. You must have a private epistemic standard higher than the social one, or else you will waste a lot of time. ([Science Isn't Strict Enough](http://lesswrong.com/lw/qd/science_isnt_strict_enough/))

It is a flaw that the teaching of Science doesn’t practice resolving confused ideas ([The Failures Of Eld Science](http://lesswrong.com/lw/q9/the_failures_of_eld_science/)), probability theory, awareness of the need for causal entanglement of belief with reality, or rationality more broadly. ([Do Scientists Already Know This Stuff?](http://lesswrong.com/lw/qe/do_scientists_already_know_this_stuff/)) Teaching probability theory alone would not correct this. ([The Definition Of Science](http://lesswrong.com/lw/qg/changing_the_definition_of_science/))

There is nothing that guarantees that you are not a fool, not even Science, not even trying to use probability theory. You don’t know your own biases, why the universe is simple enough to understand, what your priors are, or why they work. The formal math is intractable. To start as a rationalist requires losing your trust that following any prescribed pattern will keep you safe. ([No Safe Defense, Not Even Science](http://lesswrong.com/lw/qf/no_safe_defense_not_even_science/))

The bulk of work in progressing knowledge is in elevating the right hypotheses to attention, a process Science depends on but does not specify, relying on normal reasoning. ([Faster Than Science](http://lesswrong.com/lw/qi/faster_than_science/)) Einstein did this well. Most will fail, but it remains valuable to practice. ([Einstein's Speed](http://lesswrong.com/lw/qj/einsteins_speed/)) Geniuses are not separate from humanity; with grit and the right choice of problem and approach, not all but many have potential. ([Einstein's Superpowers](http://lesswrong.com/lw/qs/einsteins_superpowers/), [Class Project](http://lesswrong.com/lw/qt/class_project/))

We do not use the evidence of sensory data anywhere near optimally. ([That Alien Message](http://lesswrong.com/lw/qk/that_alien_message/)) Possible minds can be extremely smarter than humans. Basing your ideals on hypothetical extremely intelligent minds, rather than merely the best humans so far, helps you not shy away from trying to exceed them. ([My Childhood Role Model](http://lesswrong.com/lw/ql/my_childhood_role_model/))

[(Continue with "Mere Goodness")](/summaries/a-whirlwind-tour-of-lw-rationality-mere-goodness)
